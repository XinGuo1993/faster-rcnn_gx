name: "RPN_ZF"

layer {
  name: 'data'
  type: 'Python'
  top: 'data'
  top: 'labels'
  top: 'label_weights'
  top: 'bbox_targets'
  top: 'bbox_loss_weights'
  python_param {
    module: 'rpn_data_layer.layer'
    layer: 'RPNDataLayer'
    param_str: "'num_classes': 2"
  }
}

layer {
	name: "conv1"
	type: "Convolution"
	bottom: "data"
	top: "conv1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	convolution_param {
		num_output: 96
		kernel_size: 7
		pad: 3
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "relu1"
	type: "ReLU"
	bottom: "conv1"
	top: "conv1"
}

layer {
	name: "norm1"
	type: "LRN"
	bottom: "conv1"
	top: "norm1"
	lrn_param {
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
}

layer {
	name: "pool1"
	type: "Pooling"
	bottom: "norm1"
	top: "pool1"
	pooling_param {
		kernel_size: 3
		stride: 2
		pad: 1
		pool: MAX
	}
}

layer {
	name: "conv2"
	type: "Convolution"
	bottom: "pool1"
	top: "conv2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	convolution_param {
		num_output: 256
		kernel_size: 5
		pad: 2
		stride: 2
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 1
		}
	}
}

layer {
	name: "relu2"
	type: "ReLU"
	bottom: "conv2"
	top: "conv2"
}

layer {
	name: "norm2"
	type: "LRN"
	bottom: "conv2"
	top: "norm2"
	lrn_param {
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
}

layer {
	name: "pool2"
	type: "Pooling"
	bottom: "norm2"
	top: "pool2"
	pooling_param {
		kernel_size: 3
		stride: 2
		pad: 1
		pool: MAX
	}
}

layer {
	name: "conv3"
	type: "Convolution"
	bottom: "pool2"
	top: "conv3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 0
		}
	}
}

layer {
	name: "relu3"
	type: "ReLU"
	bottom: "conv3"
	top: "conv3"
}

layer {
	name: "conv4"
	type: "Convolution"
	bottom: "conv3"
	top: "conv4"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	convolution_param {
		num_output: 384
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 1
		}
	}
}

layer {
	name: "relu4"
	type: "ReLU"
	bottom: "conv4"
	top: "conv4"
}

layer {
	name: "conv5"
	type: "Convolution"
	bottom: "conv4"
	top: "conv5"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		weight_filler {
			type: "gaussian"
			std: 0.01
		}
		bias_filler {
			type: "constant"
			value: 1
		}
	}
}

layer {
	name: "relu5"
	type: "ReLU"
	bottom: "conv5"
	top: "conv5"
}

#-----------------------layer +-------------------------
layer {
   name: "conv6"
   type: "Convolution"
   bottom: "conv5"
   top: "conv6"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 256
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "relu6"
   type: "ReLU"
   bottom: "conv6"
   top: "conv6"
}

layer {
   name: "proposal_cls_score"
   type: "Convolution"
   bottom: "conv6"
   top: "proposal_cls_score"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 18   # 2(bg/fg) * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "proposal_bbox_pred"
   type: "Convolution"
   bottom: "conv6"
   top: "proposal_bbox_pred"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 36	# 4 * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

#-----------------------output------------------------

# to enable the calculation of softmax loss, we first reshape blobs related to SoftmaxWithLoss
layer {
   name: "proposal_cls_score_reshape"
   type: "Reshape"
   bottom: "proposal_cls_score"
   top: "proposal_cls_score_reshape"
   reshape_param{
	   shape {
			dim: 0 
			dim: 2
			dim: -1 
			dim: 0
		}
	}
}

layer {
   name: "labels_reshape"
   type: "Reshape"
   bottom: "labels"
   top: "labels_reshape"
   reshape_param{
	   shape {
			dim: 0 
			dim: 1
			dim: -1 
			dim: 0
		}
	}
}

layer {
   name: "label_weights_reshape"
   type: "Reshape"
   bottom: "label_weights"
   top: "label_weights_reshape"
   reshape_param{
	   shape {
			dim: 0 
			dim: 1
			dim: -1 
			dim: 0
		}
	}
}

layer {
   name: "loss_cls"
   type: "SoftmaxWithLoss"
   bottom: "proposal_cls_score_reshape"
   bottom: "labels_reshape"
   bottom: "label_weights_reshape"
   top: "loss_cls"
   loss_weight: 1
}

layer {
   name: "accuarcy"
   type: "Accuracy"
   bottom: "proposal_cls_score_reshape"
   bottom: "labels_reshape"
   top: "accuarcy"
}

layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "proposal_bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_loss_weights"
  top: "loss_bbox"
  loss_weight: 10
}